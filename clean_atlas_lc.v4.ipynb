{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Averaging ATLAS Light Curves\n",
    "### Includes chi-square cut, uncertainty cut, control light curve cut, and averaging\n",
    "\n",
    "This iPython notebook will help you apply each cut with a greater degree of control than an automatic cleaning. You will be walked through the following:\n",
    "1. Static uncertainty cut\n",
    "2. Estimating true uncertainties\n",
    "3. Dynamic chi-square cut\n",
    "4. Control light curve cut\n",
    "5. Averaging the light curve and cutting bad bins\n",
    "6. Optionally correct for ATLAS template changes\n",
    "7. Save files\n",
    "\n",
    "After running a cell, the descriptions located above that cell will help you interpret the plots and make decisions about the supernova.\n",
    "\n",
    "In order for this notebook to work correctly, the ATLAS light curves must already be downloaded and saved. Each light curve must also only include measurements for a single filter. To download SN and control light curves, please refer to the documentation `README.md` and use the download script `download_atlas_lc.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Tip:</b> Edit the following settings to correspond to your target SN and source directory for data.\n",
    "</div>\n",
    "\n",
    "\n",
    "Below we have set example fields for SN 2020lse. Recommended fields to change at a minimum include `tnsname`, `source_dir`, and `discovery_date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LOADING THE SN LIGHT CURVE #####\n",
    "\n",
    "# Enter the target SN name:\n",
    "tnsname = '2020lse'\n",
    "\n",
    "# Enter the path to the data directory that contains the SN directory:\n",
    "source_dir = f'/Users/sofiarest/Desktop/Supernovae/data/temp' \n",
    "\n",
    "# Enter the path to a directory to optionally save any plots:\n",
    "output_dir = f'{source_dir}/{tnsname}/plots'\n",
    "\n",
    "# Enter the filter for this light curve (must be 'o' or 'c'):\n",
    "filt = 'o'\n",
    "\n",
    "# Optionally, enter the SN's discovery date (if None is entered, it will be \n",
    "# fetched automatically from TNS using the API key, TNS ID, and bot name):\n",
    "discovery_date = 58985.264\n",
    "api_key = None\n",
    "tns_id = None\n",
    "bot_name = None\n",
    "\n",
    "##### LOADING CONTROL LIGHT CURVES #####\n",
    "\n",
    "# Set to True if you are planning on applying the control light curve cut \n",
    "# and have already downloaded the control light curves:\n",
    "load_controls = True\n",
    "\n",
    "# Enter the number of control light curves to load:\n",
    "n_controls = 8\n",
    "\n",
    "# Enter the source directory of the control light curve files:\n",
    "controls_dir = f'{source_dir}/{tnsname}/controls'\n",
    "\n",
    "##### PLOTTING #####\n",
    "\n",
    "# If True, try to calculate the best y limits automatically for each plot;\n",
    "# if False, leave y limits to matplotlib \n",
    "auto_xylimits = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous functions (skip this section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pdastro import pdastrostatsclass, AandB, AnotB, AorB, not_AandB\n",
    "from clean_atlas_lc_v2 import CleanAtlasLightCurve\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import warnings\n",
    "warnings.simplefilter('error', RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# plotting styles\n",
    "plt.rc('axes', titlesize = 17)\n",
    "plt.rc('xtick', labelsize = 12)\n",
    "plt.rc('ytick', labelsize = 12)\n",
    "plt.rc('legend', fontsize = 10)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['axes.prop_cycle'] = matplotlib.cycler(color=['red', 'orange', 'green', 'blue', 'purple', 'magenta'])\n",
    "matplotlib.rcParams['xtick.major.size'] = 6\n",
    "matplotlib.rcParams['xtick.major.width'] = 1\n",
    "matplotlib.rcParams['xtick.minor.size'] = 3\n",
    "matplotlib.rcParams['xtick.minor.width'] = 1\n",
    "matplotlib.rcParams['ytick.major.size'] = 6\n",
    "matplotlib.rcParams['ytick.major.width'] = 1\n",
    "matplotlib.rcParams['ytick.minor.size'] = 3\n",
    "matplotlib.rcParams['ytick.minor.width'] = 1\n",
    "matplotlib.rcParams['axes.linewidth'] = 1\n",
    "marker_size = 30\n",
    "marker_edgewidth = 1.5\n",
    "sn_flux = 'orange' if filt == 'o' else 'cyan'\n",
    "sn_flagged_flux = 'red' \n",
    "ctrl_flux = 'steelblue'\n",
    "\n",
    "# ATLAS template change dates (MJD)\n",
    "tchange1 = 58417\n",
    "tchange2 = 58882\n",
    "\n",
    "# 'Mask' column flags\n",
    "flags = {'chisquare':0x1, \n",
    "\t\t \n",
    "\t\t 'uncertainty':0x2,\n",
    "\t\t \n",
    "\t\t 'controls_bad':0x400000,\n",
    "\t\t 'controls_questionable':0x80000,\n",
    "\t\t 'controls_x2':0x100,\n",
    "\t\t 'controls_stn':0x200,\n",
    "\t\t 'controls_Nclip':0x400,\n",
    "\t\t 'controls_Ngood':0x800,\n",
    "\t\t \n",
    "\t\t 'avg_badday':0x800000,\n",
    "\t\t 'avg_ixclip':0x1000,\n",
    "\t\t 'avg_smallnum':0x2000}\n",
    "\n",
    "def do_manual_xylimits(limits):\n",
    "    for limit in limits:\n",
    "        if not limit is None:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def set_xylimits(lc, limits, control_index=0, indices=None):\n",
    "    if auto_xylimits:\n",
    "        if limits[0] is None:\n",
    "            limits[0] = lc.lcs[control_index].t['MJD'].min() * 0.999\n",
    "        if limits[1] is None:\n",
    "            limits[1] = lc.lcs[control_index].t['MJD'].max() * 1.001\n",
    "        \n",
    "        if indices is None:\n",
    "            indices = lc.get_ix()\n",
    "        # exclude measurements with duJy > 160\n",
    "        good_ix = lc.lcs[control_index].ix_inrange(colnames='duJy', uplim=160, indices=indices)\n",
    "        # get 5% of abs(max flux - min flux)\n",
    "        flux_min = lc.lcs[control_index].t.loc[good_ix, 'uJy'].min()\n",
    "        flux_max = lc.lcs[control_index].t.loc[good_ix, 'uJy'].max()\n",
    "        diff = abs(flux_max - flux_min)\n",
    "        offset = 0.05 * diff\n",
    "\n",
    "        if limits[2] is None: \n",
    "            limits[2] = flux_min - offset\n",
    "        if limits[3] is None:\n",
    "            limits[3] = flux_max + offset\n",
    "\n",
    "        return limits\n",
    "    \n",
    "    if do_manual_xylimits(limits):\n",
    "        return limits\n",
    "    \n",
    "    return None\n",
    "\n",
    "def save_plot(save_filename=None):\n",
    "    if not save_filename is None:\n",
    "        filename = f'{output_dir}/{save_filename}.png'\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        print(f'Saving plot: {filename}')\n",
    "        plt.savefig(filename, dpi=200)\n",
    "\n",
    "def plot_all_lcs(lc, add2title=None, plot_controls=False, plot_templates=False, limits=None, save_filename=None):\n",
    "    fig, ax1 = plt.subplots(1, constrained_layout=True)\n",
    "    fig.set_figwidth(7)\n",
    "    fig.set_figheight(4)\n",
    "\n",
    "    title = f'SN {tnsname} & control light curves {filt}-band flux'\n",
    "    if not(add2title is None):\n",
    "        title += add2title\n",
    "    ax1.set_title(title)\n",
    "\n",
    "    ax1.minorticks_on()\n",
    "    ax1.tick_params(direction='in', which='both')\n",
    "    ax1.set_ylabel(r'Flux ($\\mu$Jy)')\n",
    "    ax1.set_xlabel('MJD')\n",
    "    ax1.axhline(linewidth=1, color='k')\n",
    "\n",
    "    # set x and y limits\n",
    "    limits = set_xylimits(lc, limits)\n",
    "    if not limits is None:\n",
    "        ax1.set_xlim(limits[0],limits[1])\n",
    "        ax1.set_ylim(limits[2],limits[3])\n",
    "\n",
    "    if plot_templates:\n",
    "        ax1.axvline(x=tchange1, color='k', linestyle='dotted', label='ATLAS template change', zorder=100)\n",
    "        ax1.axvline(x=tchange2, color='k', linestyle='dotted', zorder=100)\n",
    "        #ax1.axvline(x=tchange2, color='k', linestyle='dotted', zorder=100)\n",
    "\n",
    "    preSN_ix = lc.get_pre_SN_ix()\n",
    "    postSN_ix = lc.get_post_SN_ix()\n",
    "\n",
    "    if load_controls and plot_controls:\n",
    "        for control_index in range(1, lc.num_controls+1):\n",
    "            plt.errorbar(lc.lcs[control_index].t['MJD'], lc.lcs[control_index].t['uJy'], yerr=lc.lcs[control_index].t[lc.dflux_colnames[control_index]], fmt='none', ecolor=ctrl_flux, elinewidth=1.5, capsize=1.2, c=ctrl_flux, alpha=0.5, zorder=0)\n",
    "            if control_index == 1:\n",
    "                plt.scatter(lc.lcs[control_index].t['MJD'], lc.lcs[control_index].t['uJy'], s=marker_size, color=ctrl_flux, marker='o', alpha=0.5, zorder=0, label=f'{lc.num_controls} control light curves')\n",
    "            else:\n",
    "                plt.scatter(lc.lcs[control_index].t['MJD'], lc.lcs[control_index].t['uJy'], s=marker_size, color=ctrl_flux, marker='o', alpha=0.5, zorder=0)\n",
    "\n",
    "\n",
    "    plt.errorbar(lc.lcs[0].t.loc[preSN_ix,'MJD'], lc.lcs[0].t.loc[preSN_ix,'uJy'], yerr=lc.lcs[0].t.loc[preSN_ix,lc.dflux_colnames[0]], fmt='none', ecolor=sn_flux, elinewidth=1, capsize=1.2, c=sn_flux, alpha=0.5, zorder=10)\n",
    "    plt.scatter(lc.lcs[0].t.loc[preSN_ix,'MJD'], lc.lcs[0].t.loc[preSN_ix,'uJy'], s=marker_size, lw=marker_edgewidth, color=sn_flux, marker='o', alpha=0.5, zorder=10, label='Pre-SN light curve')\n",
    "\n",
    "    plt.errorbar(lc.lcs[0].t.loc[postSN_ix,'MJD'], lc.lcs[0].t.loc[postSN_ix,'uJy'], yerr=lc.lcs[0].t.loc[postSN_ix,lc.dflux_colnames[0]], fmt='none', ecolor='red', elinewidth=1, capsize=1.2, c=sn_flux, alpha=0.5, zorder=10)\n",
    "    plt.scatter(lc.lcs[0].t.loc[postSN_ix,'MJD'], lc.lcs[0].t.loc[postSN_ix,'uJy'], s=marker_size, lw=marker_edgewidth, color='red', marker='o', alpha=0.5, zorder=10, label='Post-SN light curve')\n",
    "\n",
    "    ax1.legend(loc='upper right', facecolor='white', framealpha=1.0).set_zorder(100)\n",
    "\n",
    "    plt.show()\n",
    "    save_plot(save_filename=save_filename)\n",
    "\n",
    "def plot_cut_lc(lc, title, flag, limits=[None]*4, save_filename=None):\n",
    "    fig, (ax2, ax1) = plt.subplots(2, constrained_layout=True)\n",
    "    fig.set_figwidth(7)\n",
    "    fig.set_figheight(5)\n",
    "\n",
    "    fig.suptitle(f'{title} (flag {hex(flag)})')\n",
    "\n",
    "    ax1.minorticks_on()\n",
    "    ax1.tick_params(direction='in', which='both')\n",
    "    ax2.get_xaxis().set_ticks([])\n",
    "    ax1.set_ylabel(r'Flux ($\\mu$Jy)')\n",
    "    ax1.axhline(linewidth=1, color='k')\n",
    "\n",
    "    ax2.minorticks_on()\n",
    "    ax2.tick_params(direction='in', which='both')\n",
    "    ax2.set_ylabel(r'Flux ($\\mu$Jy)')\n",
    "    ax1.set_xlabel('MJD')\n",
    "    ax2.axhline(linewidth=1, color='k')\n",
    "\n",
    "    # set x and y limits\n",
    "    limits = set_xylimits(lc, limits)\n",
    "    if not limits is None:\n",
    "        ax1.set_xlim(limits[0],limits[1])\n",
    "        ax1.set_ylim(limits[2],limits[3])\n",
    "        ax2.set_xlim(limits[0],limits[1])\n",
    "        ax2.set_ylim(limits[2],limits[3])\n",
    "\n",
    "    good_ix = lc.lcs[0].ix_unmasked('Mask', maskval=flag)\n",
    "    bad_ix = lc.lcs[0].ix_masked('Mask', maskval=flag)\n",
    "\n",
    "    ax1.errorbar(lc.lcs[0].t.loc[good_ix,'MJD'], lc.lcs[0].t.loc[good_ix,'uJy'], yerr=lc.lcs[0].t.loc[good_ix,lc.dflux_colnames[0]], fmt='none', ecolor=sn_flux, elinewidth=1, capsize=1.2, c=sn_flux, alpha=0.5)\n",
    "    ax1.scatter(lc.lcs[0].t.loc[good_ix,'MJD'], lc.lcs[0].t.loc[good_ix,'uJy'], s=marker_size, lw=marker_edgewidth, color=sn_flux, marker='o', alpha=0.5, label='Kept measurements')\n",
    "\n",
    "    ax2.errorbar(lc.lcs[0].t.loc[good_ix,'MJD'], lc.lcs[0].t.loc[good_ix,'uJy'], yerr=lc.lcs[0].t.loc[good_ix,lc.dflux_colnames[0]], fmt='none', ecolor=sn_flux, elinewidth=1, capsize=1.2, c=sn_flux, alpha=0.5, zorder=5)\n",
    "    ax2.scatter(lc.lcs[0].t.loc[good_ix,'MJD'], lc.lcs[0].t.loc[good_ix,'uJy'], s=marker_size, lw=marker_edgewidth, color=sn_flux, marker='o', alpha=0.5, label='Kept measurements', zorder=5)\n",
    "\n",
    "    ax2.errorbar(lc.lcs[0].t.loc[bad_ix,'MJD'], lc.lcs[0].t.loc[bad_ix,'uJy'], yerr=lc.lcs[0].t.loc[bad_ix,lc.dflux_colnames[0]], fmt='none', ecolor=sn_flagged_flux, elinewidth=1, capsize=1.2, c=sn_flagged_flux, alpha=0.5, zorder=10)\n",
    "    ax2.scatter(lc.lcs[0].t.loc[bad_ix,'MJD'], lc.lcs[0].t.loc[bad_ix,'uJy'], s=marker_size, lw=marker_edgewidth, color=sn_flagged_flux, facecolors='none', edgecolors=sn_flagged_flux, marker='o', alpha=0.5, label='Cut measurements', zorder=10)\n",
    "\n",
    "    ax1.legend(loc='upper right', facecolor='white', framealpha=1.0).set_zorder(100)\n",
    "    ax2.legend(loc='upper right', facecolor='white', framealpha=1.0).set_zorder(100)\n",
    "\n",
    "    save_plot(save_filename=save_filename)\n",
    "    plt.show()\n",
    "\n",
    "def fdf_hist(lc, all_controls, x2bound, limits=None, density=True): \n",
    "    preSN_ix = lc.get_pre_SN_ix()\n",
    "    preSN_good_ix = lc.lcs[0].ix_inrange(colnames=['chi/N'], uplim=x2bound, indices=preSN_ix)\n",
    "    preSN_bad_ix = AnotB(preSN_ix, preSN_good_ix)\n",
    "\n",
    "    controls_ix = all_controls.t.index.values\n",
    "    controls_good_ix = all_controls.ix_inrange(colnames=['chi/N'], uplim=x2bound)\n",
    "    controls_bad_ix = AnotB(controls_ix, controls_good_ix)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2,1, constrained_layout=True)\n",
    "    fig.set_figwidth(4.5)\n",
    "    fig.set_figheight(4.5)\n",
    "\n",
    "    ax1.set_title('for pre-SN light curve', fontsize=12)\n",
    "    ax2.set_title('for control light curves', fontsize=12)\n",
    "    ax2.set_xlabel('µJy/dµJy')\n",
    "    \n",
    "    bins = None\n",
    "    if not limits is None:\n",
    "        bins = np.linspace(limits[0]-10, limits[1]+10, 20)\n",
    "        ax1.get_xaxis().set_ticks([])\n",
    "        ax1.tick_params(direction='in', which='both')\n",
    "        ax1.set_xlim(limits[0], limits[1])\n",
    "        ax2.tick_params(direction='in', which='both')\n",
    "        ax2.set_xlim(limits[0], limits[1])\n",
    "\n",
    "    ax1.hist(lc.lcs[0].t.loc[preSN_good_ix,'uJy/duJy'], bins=bins, color='green', alpha=0.5, label=f'Data with chi-square<{x2bound}', density=density)\n",
    "    ax1.hist(lc.lcs[0].t.loc[preSN_bad_ix,'uJy/duJy'], bins=bins, color='red', alpha=0.5, label=f'Data with chi-square≥{x2bound}', density=density)\n",
    "    \n",
    "    ax2.hist(all_controls.t.loc[controls_good_ix,'uJy/duJy'], bins=bins, color='green', alpha=0.5, density=density)\n",
    "    ax2.hist(all_controls.t.loc[controls_bad_ix,'uJy/duJy'], bins=bins, color='red', alpha=0.5, density=density)\n",
    "\n",
    "    fig.legend(facecolor='white', framealpha=1, loc='upper left',  bbox_to_anchor=(1, 1))\n",
    "    plt.show()\n",
    "\n",
    "def fdf_hist_preSNonly(lc, x2bound, limits=None, density=True):\n",
    "    preSN_ix = lc.get_pre_SN_ix()\n",
    "    preSN_good_ix = lc.lcs[0].ix_inrange(colnames=['chi/N'], uplim=x2bound, indices=preSN_ix)\n",
    "    preSN_bad_ix = AnotB(preSN_ix, preSN_good_ix)\n",
    "\n",
    "    fig, ax1 = plt.subplots(1, constrained_layout=True)\n",
    "    fig.set_figwidth(4.5)\n",
    "    fig.set_figheight(2.5)\n",
    "\n",
    "    ax1.set_title('for pre-SN light curve', fontsize=12)\n",
    "    ax1.set_xlabel('µJy/dµJy')\n",
    "    \n",
    "    bins = None\n",
    "    if not limits is None:\n",
    "        bins = np.linspace(limits[0]-10, limits[1]+10, 20)\n",
    "        ax1.tick_params(direction='in', which='both')\n",
    "        ax1.set_xlim(limits[0], limits[1])\n",
    "    \n",
    "    ax1.hist(lc.lcs[0].t.loc[preSN_good_ix,'uJy/duJy'], bins=bins, color='green', alpha=0.5, label=f'Data with chi-square<{x2bound}', density=density)\n",
    "    ax1.hist(lc.lcs[0].t.loc[preSN_bad_ix,'uJy/duJy'], bins=bins, color='red', alpha=0.5, label=f'Data with chi-square≥{x2bound}', density=density)\n",
    "\n",
    "    fig.legend(facecolor='white', framealpha=1, loc='upper left',  bbox_to_anchor=(1, 1))\n",
    "    plt.show()\n",
    "\n",
    "def plot_limcuts(limcuts, x2_cut, limits=None, use_preSN_lc=False):\n",
    "    loss_color = 'darkmagenta'\n",
    "    contam_color = 'teal'\n",
    "\n",
    "    fig, ax1 = plt.subplots(1, constrained_layout=True)\n",
    "    fig.set_figwidth(5.5)\n",
    "    fig.set_figheight(3)\n",
    "\n",
    "    #ax1.set_title(f'SN {tnsname} {filt}-band chi-square cut')\n",
    "\n",
    "    ax1.minorticks_on()\n",
    "    ax1.tick_params(direction='in', which='both')\n",
    "    if use_preSN_lc:\n",
    "        ax1.set_ylabel(f'% pre-SN light curve measurements')\n",
    "    else:\n",
    "        ax1.set_ylabel(f'% control light curve measurements')\n",
    "    ax1.set_xlabel('Chi-square cut')\n",
    "    ax1.axhline(linewidth=1, color='k')\n",
    "\n",
    "    ax1.plot(limcuts['PSF Chi-Square Cut'].values, limcuts['Ploss'].values, ms=3.5, color=loss_color, marker='o', label='Loss')\n",
    "    ax1.plot(limcuts['PSF Chi-Square Cut'].values, limcuts['Pcontamination'].values, ms=3.5, color=contam_color, marker='o', label='Contamination')\n",
    "\n",
    "    ax1.axvline(x2_cut, color='k', linestyle='dashed', label='Selected cut')\n",
    "\n",
    "    ax1.set_xlim(0,50)\n",
    "    ax1.set_ylim(0, max(max(limcuts['Ploss']), max(limcuts['Pcontamination']))*1.1)\n",
    "    if not limits is None:\n",
    "        ax1.set_xlim(limits[0], limits[1])\n",
    "        ax1.set_ylim(limits[2], limits[3])\n",
    "\n",
    "    ax1.legend(facecolor='white', framealpha=1, bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def hist_stats(stats, use_preSN_lc=False):\n",
    "    fig, ax1 = plt.subplots(1, constrained_layout=True)\n",
    "    fig.set_figwidth(5)\n",
    "    fig.set_figheight(4)\n",
    "    #if use_preSN_lc:\n",
    "    #    ax1.set_title('Distributions across pre-SN light curve')\n",
    "    #else:\n",
    "    ax1.set_title('Distributions across control light curves')\n",
    "    ax1.tick_params(direction='in', which='both')\n",
    "    ax1.set_ylabel(f'Freq')\n",
    "\n",
    "    max_y = max(max(stats['median_dflux']), max(stats['stdev']), max(stats['sigma_extra']))\n",
    "    bins = np.linspace(0, max_y+3, 10)\n",
    "    median_sigma_extra = np.median(stats['sigma_extra'])\n",
    "    \n",
    "    ax1.hist(stats['median_dflux'], bins=bins, alpha=0.5, label=r'median $\\delta uJy$')\n",
    "    \n",
    "    ax1.hist(stats['stdev'], bins=bins, alpha=0.5, label=r'$\\sigma_{uJy}$')\n",
    "\n",
    "    ax1.hist(stats['sigma_extra'], bins=bins, alpha=0.5, label=r'$\\sigma_{extra}$')\n",
    "    ax1.axvline(median_sigma_extra, color='green', label=r'median $\\sigma_{extra}$')\n",
    "\n",
    "    ax1.legend(facecolor='white', framealpha=1, loc='upper left',  bbox_to_anchor=(1, 1))\n",
    "    plt.show()\n",
    "\n",
    "def plot_true_uncertainties(lc, limits=None, save_filename=None):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, constrained_layout=True)\n",
    "    fig.set_figwidth(7)\n",
    "    fig.set_figheight(5)\n",
    "\n",
    "    ax1.set_title(f'SN {tnsname} {filt}-band flux\\nbefore true uncertainties estimation')\n",
    "    ax1.minorticks_on()\n",
    "    ax1.tick_params(direction='in', which='both')\n",
    "    ax1.get_xaxis().set_ticks([])\n",
    "    ax1.set_ylabel(r'Flux ($\\mu$Jy)')\n",
    "    ax1.axhline(linewidth=1, color='k')\n",
    "\n",
    "    ax2.set_title(f'after true uncertainties estimation')\n",
    "    ax2.minorticks_on()\n",
    "    ax2.tick_params(direction='in', which='both')\n",
    "    ax2.set_ylabel(r'Flux ($\\mu$Jy)')\n",
    "    ax2.set_xlabel('MJD')\n",
    "    ax2.axhline(linewidth=1, color='k')\n",
    "\n",
    "    # set x and y limits\n",
    "    limits = set_xylimits(lc, limits)\n",
    "    if not limits is None:\n",
    "        ax1.set_xlim(limits[0],limits[1])\n",
    "        ax1.set_ylim(limits[2],limits[3])\n",
    "        ax2.set_xlim(limits[0],limits[1])\n",
    "        ax2.set_ylim(limits[2],limits[3])\n",
    "\n",
    "    ax1.errorbar(lc.lcs[0].t['MJD'], lc.lcs[0].t['uJy'], yerr=lc.lcs[0].t['duJy'], fmt='none', ecolor=sn_flux, elinewidth=1, capsize=1.2, c=sn_flux, alpha=0.5)\n",
    "    ax1.scatter(lc.lcs[0].t['MJD'], lc.lcs[0].t['uJy'], s=marker_size, lw=marker_edgewidth, color=sn_flux, marker='o', alpha=0.5)\n",
    "\n",
    "    ax2.errorbar(lc.lcs[0].t['MJD'], lc.lcs[0].t['uJy'], yerr=lc.lcs[0].t['duJy_new'], fmt='none', ecolor=sn_flux, elinewidth=1, capsize=1.2, c=sn_flux, alpha=0.5)\n",
    "    ax2.scatter(lc.lcs[0].t['MJD'], lc.lcs[0].t['uJy'], s=marker_size, lw=marker_edgewidth, color=sn_flux, marker='o', alpha=0.5)\n",
    "\n",
    "    save_plot(save_filename=save_filename)\n",
    "    plt.show()\n",
    "\n",
    "# 3-panel plot of (1) template regions in different colors and (2) zoom-in on transitions\n",
    "def plot_template_correction(lc, limits=None):\n",
    "    colors = ['salmon', 'sandybrown', 'darkseagreen']\n",
    "    \n",
    "    t1, t2 = 58417, 58882\n",
    "    region1_ix = lc.lcs[0].ix_inrange('MJD', uplim=t1)\n",
    "    region2_ix = lc.lcs[0].ix_inrange('MJD', lowlim=t1, uplim=t2)\n",
    "    region3_ix = lc.lcs[0].ix_inrange('MJD', lowlim=t2)\n",
    "\n",
    "    region1_mean = lc._get_mean(region1_ix[-40:]) # last 40 measurements before t1\n",
    "    region2a_mean = lc._get_mean(region2_ix[:40]) # first 40 measurements after t1\n",
    "    region2b_mean = lc._get_mean(region2_ix[-40:]) # last 40 measurements before t2\n",
    "    region3_mean = lc._get_mean(region3_ix[:40]) # first 40 measurements after t2\n",
    "\n",
    "    gs = gridspec.GridSpec(2, 2, height_ratios=[1, 1], hspace=0.35, wspace=0.4)\n",
    "    fig = plt.figure()\n",
    "    fig.set_figwidth(6)\n",
    "    fig.set_figheight(6)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    ax1 = plt.subplot(gs[0, :])\n",
    "    ax1.axvline(x=t1, color='k', linestyle='dotted', label='ATLAS template change', zorder=100)\n",
    "    ax1.axvline(x=t2, color='k', linestyle='dotted', zorder=100)\n",
    "    ax1.axhline(color='k',zorder=0)\n",
    "    limits = set_xylimits(lc, limits)\n",
    "    ax1.set_xlim(limits[0], limits[1])\n",
    "    ax1.set_ylim(limits[2], limits[3])\n",
    "\n",
    "    ax1.errorbar(lc.lcs[0].t.loc[region1_ix,'MJD'], lc.lcs[0].t.loc[region1_ix,'uJy'], yerr=lc.lcs[0].t.loc[region1_ix,lc.dflux_colnames[0]], fmt='none', ecolor=colors[0], elinewidth=1, capsize=1.2, c=sn_flux, alpha=0.5, zorder=10)\n",
    "    ax1.scatter(lc.lcs[0].t.loc[region1_ix,'MJD'], lc.lcs[0].t.loc[region1_ix,'uJy'], s=marker_size, lw=marker_edgewidth, color=colors[0], marker='o', alpha=0.5, zorder=10, label='Region 1 flux')\n",
    "    ax1.errorbar(lc.lcs[0].t.loc[region2_ix,'MJD'], lc.lcs[0].t.loc[region2_ix,'uJy'], yerr=lc.lcs[0].t.loc[region2_ix,lc.dflux_colnames[0]], fmt='none', ecolor=colors[1], elinewidth=1, capsize=1.2, c=sn_flux, alpha=0.5, zorder=10)\n",
    "    ax1.scatter(lc.lcs[0].t.loc[region2_ix,'MJD'], lc.lcs[0].t.loc[region2_ix,'uJy'], s=marker_size, lw=marker_edgewidth, color=colors[1], marker='o', alpha=0.5, zorder=10, label='Region 2 flux')\n",
    "    ax1.errorbar(lc.lcs[0].t.loc[region3_ix,'MJD'], lc.lcs[0].t.loc[region3_ix,'uJy'], yerr=lc.lcs[0].t.loc[region3_ix,lc.dflux_colnames[0]], fmt='none', ecolor=colors[2], elinewidth=1, capsize=1.2, c=sn_flux, alpha=0.5, zorder=10)\n",
    "    ax1.scatter(lc.lcs[0].t.loc[region3_ix,'MJD'], lc.lcs[0].t.loc[region3_ix,'uJy'], s=marker_size, lw=marker_edgewidth, color=colors[2], marker='o', alpha=0.5, zorder=10, label='Region 2 flux')\n",
    "\n",
    "    ax1.legend(facecolor='white', framealpha=1, loc='upper left',  bbox_to_anchor=(1, 1))\n",
    "\n",
    "    ax2 = plt.subplot(gs[1, 0])\n",
    "    ax2.axvline(x=t1, color='k', linestyle='dotted', zorder=100)\n",
    "    ax2.axhline(color='k',zorder=0)\n",
    "    ax2.set_xlim(lc.lcs[0].t.loc[region1_ix[-40:][0], 'MJD'], lc.lcs[0].t.loc[region2_ix[:40][-1], 'MJD'])\n",
    "\n",
    "    ax2.errorbar(lc.lcs[0].t.loc[region1_ix,'MJD'], lc.lcs[0].t.loc[region1_ix,'uJy'], yerr=lc.lcs[0].t.loc[region1_ix,lc.dflux_colnames[0]], fmt='none', ecolor=colors[0], elinewidth=1, capsize=1.2, c=sn_flux, alpha=0.5, zorder=10)\n",
    "    ax2.scatter(lc.lcs[0].t.loc[region1_ix,'MJD'], lc.lcs[0].t.loc[region1_ix,'uJy'], s=marker_size, lw=marker_edgewidth, color=colors[0], marker='o', alpha=0.5, zorder=10)\n",
    "    ax2.errorbar(lc.lcs[0].t.loc[region2_ix,'MJD'], lc.lcs[0].t.loc[region2_ix,'uJy'], yerr=lc.lcs[0].t.loc[region2_ix,lc.dflux_colnames[0]], fmt='none', ecolor=colors[1], elinewidth=1, capsize=1.2, c=sn_flux, alpha=0.5, zorder=10)\n",
    "    ax2.scatter(lc.lcs[0].t.loc[region2_ix,'MJD'], lc.lcs[0].t.loc[region2_ix,'uJy'], s=marker_size, lw=marker_edgewidth, color=colors[1], marker='o', alpha=0.5, zorder=10)\n",
    "\n",
    "    ax2.axhline(y=region1_mean, color=colors[0], linestyle='dashed', label='Region 1 mean')\n",
    "    ax2.axhline(y=region2a_mean, color=colors[1], linestyle='dashed', label='Region 2 mean')\n",
    "\n",
    "    limits = set_xylimits(lc, limits, indices=AorB(region1_ix[-40:], region2_ix[:40]))\n",
    "    ax2.set_ylim(limits[2], limits[3])\n",
    "    ax2.legend(facecolor='white', framealpha=1)\n",
    "\n",
    "    ax3 = plt.subplot(gs[1, 1]) \n",
    "    ax3.axvline(x=t2, color='k', linestyle='dotted', zorder=100)\n",
    "    ax3.axhline(color='k',zorder=0)\n",
    "    ax3.set_xlim(lc.lcs[0].t.loc[region2_ix[-40:][0], 'MJD'], lc.lcs[0].t.loc[region3_ix[:40][-1], 'MJD'])\n",
    "    ax3.set_ylim(limits[2], limits[3])\n",
    "\n",
    "    ax3.errorbar(lc.lcs[0].t.loc[region2_ix,'MJD'], lc.lcs[0].t.loc[region2_ix,'uJy'], yerr=lc.lcs[0].t.loc[region2_ix,lc.dflux_colnames[0]], fmt='none', ecolor=colors[1], elinewidth=1, capsize=1.2, c=sn_flux, alpha=0.5, zorder=10)\n",
    "    ax3.scatter(lc.lcs[0].t.loc[region2_ix,'MJD'], lc.lcs[0].t.loc[region2_ix,'uJy'], s=marker_size, lw=marker_edgewidth, color=colors[1], marker='o', alpha=0.5, zorder=10)\n",
    "    ax3.errorbar(lc.lcs[0].t.loc[region3_ix,'MJD'], lc.lcs[0].t.loc[region3_ix,'uJy'], yerr=lc.lcs[0].t.loc[region3_ix,lc.dflux_colnames[0]], fmt='none', ecolor=colors[2], elinewidth=1, capsize=1.2, c=sn_flux, alpha=0.5, zorder=10)\n",
    "    ax3.scatter(lc.lcs[0].t.loc[region3_ix,'MJD'], lc.lcs[0].t.loc[region3_ix,'uJy'], s=marker_size, lw=marker_edgewidth, color=colors[2], marker='o', alpha=0.5, zorder=10)\n",
    "\n",
    "    ax3.axhline(y=region2b_mean, color=colors[1], linestyle='dashed', label='Region 2 mean')\n",
    "    ax3.axhline(y=region3_mean, color=colors[2], linestyle='dashed', label='Region 3 mean')\n",
    "\n",
    "    limits = set_xylimits(lc, limits, indices=AorB(region2_ix[-40:], region3_ix[:40]))\n",
    "    ax3.set_ylim(limits[2], limits[3])\n",
    "    ax3.legend(facecolor='white', framealpha=1)\n",
    "\n",
    "    for ax in (ax1, ax2, ax3):\n",
    "        ax.minorticks_on()\n",
    "        ax.tick_params(direction='in', which='both')\n",
    "        ax.set_xlabel('MJD')\n",
    "        ax.set_ylabel('uJy')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def write_to_f(f, text):\n",
    "    try:\n",
    "        f.write(text)\n",
    "    except Exception:\n",
    "        print('WARNING: Could not save output text to output file')\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the ATLAS light curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'SN {tnsname}, filter {filt}, {n_controls} control light curves')\n",
    "if not discovery_date is None:\n",
    "    print(f'SN discovery date: {discovery_date}')\n",
    "print(f'Source directory (load SN light curve): {source_dir}/{tnsname}')\n",
    "if load_controls: \n",
    "    print(f'Controls directory (load control light curves): {controls_dir}')\n",
    "print(f'Output directory (save plots): {output_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filt != 'o' and filt != 'c': \n",
    "\traise RuntimeError('Filter must be \"o\" or \"c\"!')\n",
    "lc = CleanAtlasLightCurve(filt, tnsname=tnsname, discdate=discovery_date)\n",
    "\n",
    "# get discovery date\n",
    "if lc.discdate is None:\n",
    "\tlc._get_tns_data(tnsname, api_key, tns_id, bot_name)\n",
    "\t\n",
    "# new text file that will contain record of each cut, etc.\n",
    "f = open(f'{source_dir}/{lc.tnsname}/{lc.tnsname}_output.md', 'w')\n",
    "f = write_to_f(f, f'# SN {lc.tnsname} Light Curve Cleaning and Averaging\\n\\nFilter: {lc.filt}-band\\nDiscovery date: {lc.discdate}\\nNumber of control light curves: {n_controls}')\n",
    "\n",
    "# load SN and control light curves\n",
    "lc._load(source_dir, filt, n_controls)\n",
    "\n",
    "print('\\nPreparing for cleaning...')\n",
    "lc.prep_for_cleaning()\n",
    "print(lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot SN and control light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot control light curves underneath SN light curve?\n",
    "plot_controls = True\n",
    "\n",
    "# Optionally, manually enter the x and y limits:\n",
    "xlim_lower = None\n",
    "xlim_upper = None\n",
    "ylim_lower = None\n",
    "ylim_upper = None\n",
    "\n",
    "limits = [xlim_lower, xlim_upper, ylim_lower, ylim_upper]\n",
    "plot_all_lcs(lc, plot_controls=plot_controls, plot_templates=True, limits=limits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Static uncertainty cut\n",
    "\n",
    "The following uncertainty cut implements a static cut that applies the same way to each light curve. The purpose of this cut is to identify and clean out the most egregious outliers with large uncertainties and small chi-square values that would not be cut out in the dynamic chi-square cut. The default value of this cut (160) was determined after calculating the typical uncertainty of bright stars just below the saturation limit. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning:</b> If the SN is particularly bright, you may want to increase the value of the cut and rerun this portion.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may change the following static uncertainty cut value to your liking;\n",
    "# however, the default value is 160.\n",
    "uncertainty_cut = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = lc._apply_uncert_cut(flags['uncertainty'], uncertainty_cut)\n",
    "f = write_to_f(f, f'\\n\\n## Uncertainty cut\\n{output}')\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the uncertainty cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the light curve before and after the applied uncertainty cut?:\n",
    "plot = True\n",
    "\n",
    "# Optionally, manually enter the x and y limits for the uncertainty cut plot:\n",
    "xlim_lower = None\n",
    "xlim_upper = None\n",
    "ylim_lower = None\n",
    "ylim_upper = None\n",
    "\n",
    "if plot:\n",
    "    limits = [xlim_lower, xlim_upper, ylim_lower, ylim_upper]\n",
    "    plot_cut_lc(lc, 'Uncertainty cut', flags['uncertainty'], limits=limits, save_filename='uncertainty_cut')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Estimating true uncertainties by calculating a systematic error contribution\n",
    "\n",
    "This section attempts to account for an extra noise source in the data by estimating the true typical uncertainty, deriving the additional systematic uncertainty, and lastly applying this extra noise to a new uncertainty column. This new uncertainty column will be used in the cuts following this section.\n",
    "\n",
    "Note: We refer to flux as $\\mu Jy$ and to the uncertainties as $\\delta \\mu Jy$, as they are referred to in the ATLAS light curve columns.\n",
    "\n",
    "Here is the procedure we use:\n",
    "1. We use the control light curves for this analysis since we don't have to worry about any real astrophysical flux in the light curves. We apply the uncertainty cut described above, and also apply a preliminary cut on the PSF fit chi-square cut at 20 (default value). Any measurements flagged by these two cuts are filtered out.  \n",
    "2. From these measurements, (1) calculate the typical uncertainty $\\delta \\mu Jy_{\\text{typical}}$ as the median of the nominal uncertainties in the $\\delta \\mu Jy$ column. (2) We calculate the true typical error as the 3-sigma clipped standard deviation $\\sigma_{\\mu Jy}$ of the flux in the uJy column. In the ideal world, $\\delta \\mu Jy_{\\text{typical}}$ $\\approx$ $\\sigma_{\\mu Jy}$. However, there are often additional error sources, and we calculate the sum of these additional error sources $\\sigma_{extra}$ for each control light curve using the following relation (we set $\\sigma_{extra}=0.0$ if $\\sigma_{\\mu Jy}$<$\\delta \\mu Jy_{\\text{typical}}$):\n",
    "       \n",
    "    - $\\sigma_{\\mu Jy}^2$ = $\\delta \\mu Jy_{\\text{typical}}^2$ +  $\\sigma_{extra}^2$\n",
    "\n",
    "3. Calculate the final extra noise source by taking the median of all $\\sigma_{extra}$.\n",
    "4. Apply the extra noise source to the existing uncertainty using the following formula:\n",
    "    - $\\delta \\mu Jy_{new}^2 = \\delta \\mu Jy^2 + \\sigma_{extra}^2$\n",
    "6. For cuts following this procedure, use the new uncertainty column with the extra noise added instead of the old uncertainty column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter a preliminary chi-square cut (keep at a high number; default is 20):\n",
    "prelim_x2_cut = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_uncert_est(lc, uncert_flag, prelim_x2_cut):\n",
    "    print('\\nApplying true uncertainty estimation...')\n",
    "\n",
    "    stats = lc._get_uncert_est_stats(uncert_flag, prelim_x2_cut)\n",
    "    print(stats)\n",
    "    hist_stats(stats)\n",
    "    final_sigma_extra = lc._get_final_sigma_extra(stats)\n",
    "    print(f'# Final sigma extra: {final_sigma_extra:0.2f}')\n",
    "    \n",
    "    sigma_typical_old = np.median(stats['median_dflux'])\n",
    "    sigma_typical_new = np.sqrt(final_sigma_extra**2 + sigma_typical_old**2)\n",
    "    percent_greater = 100 * ((sigma_typical_new - sigma_typical_old)/sigma_typical_old)\n",
    "    \n",
    "    s1 = f'We increase the typical uncertainties from {sigma_typical_old:0.2f} to {sigma_typical_new:0.2f} by adding an additional systematic uncertainty of {final_sigma_extra:0.2f} in quadrature'\n",
    "    print(f'# {s1}')\n",
    "    print(f'# New typical uncertainty is {percent_greater:0.2f}% greater than old typical uncertainty')\n",
    "    if percent_greater >= 10:\n",
    "        answer = input('True uncertainties estimation recommended. Proceed? (y/n)')\n",
    "        if answer == 'y':\n",
    "            print('# Calculating new uncertainties in \\'duJy_new\\' column for each light curve...') \n",
    "            output = f'{s1}\\nThe extra noise was added to the uncertainties of the SN light curve and copied to the \"duJy_new\" column'\n",
    "            lc._add_noise(final_sigma_extra)\n",
    "    \n",
    "            print('Success')\n",
    "            print('Quick sanity check:')\n",
    "            print(lc.lcs[0].t[['MJD', 'uJy', 'duJy', 'duJy_new']].head())\n",
    "            \n",
    "            #if plot:\n",
    "            #    plot_true_uncertainties(lc, limits=limits, save_filename='true_uncerts')\n",
    "        else:\n",
    "            s2 = 'Skipping procedure'\n",
    "            output = f'{s2}'\n",
    "            print(f'# {s2}')\n",
    "    else:\n",
    "        s3 = f'True uncertainties estimation not needed; skipping procedure'\n",
    "        output = f'{s3}.'\n",
    "        print(s3)\n",
    "    return lc, output\n",
    "\n",
    "lc, output = apply_uncert_est(lc, flags['uncertainty'], prelim_x2_cut)\n",
    "f = write_to_f(f, f'\\n\\n## True uncertainties estimation\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the true uncertainties estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the light curve before and after estimating true uncertainties?:\n",
    "plot = True\n",
    "\n",
    "# Optionally, manually enter the x and y limits for the plot:\n",
    "xlim_lower = None\n",
    "xlim_upper = None\n",
    "ylim_lower = None\n",
    "ylim_upper = None\n",
    "\n",
    "if plot and 'duJy_new' in lc.lcs[0].t.columns:\n",
    "    plot_true_uncertainties(lc, limits=limits, save_filename='true_uncerts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Dynamic chi-square cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use two factors, <strong>contamination</strong> and <strong>loss</strong>, to analyze a PSF chi-square cut for the target SN, with flux/dflux as the deciding factor of what constitutes a good measurement vs. a bad measurement. \n",
    "\n",
    "We decide what will determine a good measurement vs. a bad measurement using a factor outside of the chi-square values. Our chosen factor is the absolute value of flux (µJy) divided by dflux (dµJy). The recommended boundary is a value of 3, such that any measurements with |µJy/dµJy| <= 3 are regarded as \"good\" measurements, and any measurements with |µJy/dµJy| > 3 are regarded as \"bad\" measurements. You can set this boundary to a different number by changing the value of `fdf_bound` below. \n",
    "\n",
    "We aim to separate good measurements from bad using the calculated chi-square cut by <strong>minimizing as much loss *and* contamination as possible</strong>. \n",
    "- We define contamination $C$ for a certain chi-square cut to be the number of bad kept measurements over the total number of kept measurements.\n",
    "    - $C = N_{bad, kept}/N_{kept}$\n",
    "- We define loss $L$ for a certain chi-square cut to be the number of good cut measurements over the total number of good measurements.\n",
    "    - $L = N_{good,cut}/N_{good}$\n",
    "- We set the upper and lower bounds of a range of possible cuts for which to calculate $C$ and $L$. We start at a low value of 3 (which can be changed by setting the value of `cut_start` below) and end at 50 (this value is inclusive and can be changed by setting the value of `cut_stop` below) with a step size of 1 (`cut_step` below). For chi-square cuts falling on or between `cut_start` and `cut_stop` in increments of `cut_step`, we can begin to calculate contamination and loss percentages.\n",
    "- Since we can assume that the expected value of the control light curve flux is 0, we use these measurements by default to calculate and plot contamination and loss for the range of possible cuts.\n",
    "\n",
    "We set our default chi-square cut to 5, and defer overriding of that cut for a particular SN to the user, given informative plots on alternative cuts with respect to contamination and loss. The user can override this cut by changing the `x2_cut` field and rerunning the following cells.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> For very bright SNe, the chi-square values may increase during the SN even for good measurements due to imperfection in PSF fitting. Therefore, we recommend that the user double-check the chi-square values (or this section's plots) to verify that the cut is working as intended, and override the cut with a custom value if needed. The user can rerun the following cells in order to reapply a custom cut.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may change the following PSF chi-square cut value to your liking;\n",
    "# however, the default value is 5.\n",
    "x2_cut = 5\n",
    "\n",
    "# Enter the bound that should separate a good |flux/dflux| measurement from a bad one\n",
    "# (will be used when calculating contamination and loss):\n",
    "fdf_bound = 3.0\n",
    "\n",
    "# Enter the bounds for the range of possible chi-square cuts for which to \n",
    "# calculate contamination and loss (minimum cut, maximum cut, and step):\n",
    "cut_start = 3 # this is inclusive\n",
    "cut_stop = 50 # this is inclusive\n",
    "cut_step = 1\n",
    "\n",
    "# If set to True, we use the pre-SN light curve to calculate contamination and loss.\n",
    "# If set to False, we use the control light curves (recommended).\n",
    "use_preSN_lc = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percent_greater(a, b):\n",
    "    return 100 * ((a - b)/b)\n",
    "\n",
    "def sanity_check(lc, all_controls, chisquare_cut):\n",
    "    postSN_ix = lc.get_post_SN_ix()\n",
    "    postSN_kept_ix, postSN_cut_ix = lc._get_keptcut_ix(lc.lcs[0], postSN_ix, chisquare_cut)\n",
    "    postSN_percent_cut = len(postSN_cut_ix)/len(postSN_ix)\n",
    "\n",
    "    preSN_ix = lc.get_pre_SN_ix()\n",
    "    preSN_kept_ix, preSN_cut_ix = lc._get_keptcut_ix(lc.lcs[0], preSN_ix, chisquare_cut)\n",
    "    preSN_percent_cut = len(preSN_cut_ix)/len(preSN_ix)\n",
    "\n",
    "    controls_ix = all_controls.t.index.values\n",
    "    controls_kept_ix, controls_cut_ix = lc._get_keptcut_ix(all_controls, controls_ix, chisquare_cut)\n",
    "    controls_percent_cut = len(controls_cut_ix)/len(controls_ix)\n",
    "\n",
    "    postSN_percent_greater = get_percent_greater(postSN_percent_cut, controls_percent_cut)\n",
    "    preSN_percent_greater = get_percent_greater(preSN_percent_cut, controls_percent_cut)\n",
    "\n",
    "    print('\\nSanity check:')\n",
    "    print(f'# {controls_percent_cut:0.4f}% of measurements cut in control light curves')\n",
    "\n",
    "    out = f'{preSN_percent_cut:0.4f}% of measurements cut in pre-SN light curve'\n",
    "    if preSN_percent_greater >= 50:\n",
    "        out = f'# WARNING: {out} (increase by a factor of approx. {preSN_percent_greater/100+1:0.2f})'\n",
    "        out += f'\\n  Bright SNe may cause the chi-square values to increase even at good measurements due to PSF fitting imperfections. Please double check the plot.'\n",
    "    else:\n",
    "        out = f'# {out}'\n",
    "    print(out)\n",
    "    \n",
    "    out = f'{postSN_percent_cut:0.4f}% of measurements cut during and after SN discovery date'\n",
    "    if postSN_percent_greater >= 50:\n",
    "        out = f'# WARNING: {out} (increase by a factor of approx. {postSN_percent_greater/100+1:0.2f})'\n",
    "        out += f'\\n  Bright SNe may cause the chi-square values to increase even at good measurements due to PSF fitting imperfections. Please double check the plot.'\n",
    "    else:\n",
    "        out = f'# {out}'\n",
    "    print(out)\n",
    "\n",
    "def select_x2_cut(x2_cut, lc_temp, ix, good_ix, bad_ix):\n",
    "    data = lc._get_limcuts_data(lc_temp, x2_cut, ix, good_ix, bad_ix)\n",
    "    print(f'# Selected chi-square cut of {x2_cut:0.2f}, with contamination of {data[\"Pcontamination\"]:0.2f}% and loss of {data[\"Ploss\"]:0.2f}')\n",
    "    return data\n",
    "\n",
    "if load_controls:\n",
    "    all_controls = lc._get_all_controls()\n",
    "\n",
    "if use_preSN_lc or not load_controls:\n",
    "    lc_temp = lc.lcs[0]\n",
    "    ix = lc_temp.ix_inrange('MJD', uplim=discovery_date)\n",
    "else:\n",
    "    lc_temp = all_controls\n",
    "    ix = lc_temp.t.index.values\n",
    "\n",
    "good_ix, bad_ix = lc._get_goodbad_ix(lc_temp, ix, fdf_bound)\n",
    "\n",
    "# get contamination and loss for range of possible cuts\n",
    "limcuts = lc._get_limcuts_table(lc_temp, ix, good_ix, bad_ix, cut_start, cut_stop, cut_step)\n",
    "\n",
    "# get contamination and loss for selected cut\n",
    "data = select_x2_cut(x2_cut, lc_temp, ix, good_ix, bad_ix)\n",
    "\n",
    "output = lc._apply_x2_cut(x2_cut, data, flags['chisquare'])[2]\n",
    "if load_controls:\n",
    "    sanity_check(lc, all_controls, x2_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the flux/dflux distribution\n",
    "\n",
    "The following histogram displays the flux/dflux distribution of the SN and control light curves. In green, we plot flux/dflux (µJy/dµJy) measurements with a chi-square value less than or equal to `x2_cut`, which is currently set to 5 below; in red, we plot flux/dflux (µJy/dµJy) measurements with a chi-square value greater than `x2_cut`. \n",
    "\n",
    "Ideally, all measurements with chi-square value <= `x2_cut` should have |µJy/dµJy| <= `fdf_bound`, and measurements with chi-square > `x2_cut` should have |µJy/dµJy| > `fdf_bound`. Our goal is to separate good measurements from bad measurements using a chi-square cut; in order for our cut to be effective, this histogram should hopefully showcase this relation between the target SN's |µJy/dµJy| and chi-square measurements.\n",
    "\n",
    "Note that the histogram will show <strong>probability density</strong> so as to ease comparison between the groups plotted within each histogram. You can change this by toggling the `density` field below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the flux/dflux distribution?:\n",
    "plot = True\n",
    "\n",
    "# Optionally, use probability density (if True, each bin will display the bin's raw count divided by total count and bin width)\n",
    "density = True\n",
    "\n",
    "# Optionally, manually enter the histogram's x limits here:\n",
    "xlim_lower = -30\n",
    "xlim_upper = 30\n",
    "\n",
    "if plot:\n",
    "    if use_preSN_lc or not load_controls:\n",
    "        fdf_hist_preSNonly(lc, x2_cut, limits=[xlim_lower, xlim_upper], density=density)\n",
    "    else:\n",
    "        fdf_hist(lc, all_controls, x2_cut, limits=[xlim_lower, xlim_upper], density=density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss and contamination for range of chi-square cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and contamination for a series of possible chi-square cuts?\n",
    "plot = True\n",
    "\n",
    "# Optionally, manually enter the x and y limits for the contamination and loss plot:\n",
    "xlim_lower = None\n",
    "xlim_upper = None\n",
    "ylim_lower = None\n",
    "ylim_upper = None\n",
    "\n",
    "if plot:\n",
    "    limits = [xlim_lower, xlim_upper, ylim_lower, ylim_upper]\n",
    "    plot_limcuts(limcuts, x2_cut, limits=limits, use_preSN_lc=use_preSN_lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply and plot the selected chi-square cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the light curve before and after the applied chi-square cut?:\n",
    "plot = True\n",
    "\n",
    "# Optionally, manually enter the x and y limits for the chi-square cut plot:\n",
    "xlim_lower = None\n",
    "xlim_upper = None\n",
    "ylim_lower = None\n",
    "ylim_upper = None\n",
    "\n",
    "if plot:\n",
    "    limits = [xlim_lower, xlim_upper, ylim_lower, ylim_upper]\n",
    "    plot_cut_lc(lc, 'Chi-square cut', flags['chisquare'], limits=limits, save_filename='chisquare_cut')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Control light curves:  3σ-clipped average cut\n",
    "\n",
    "While the chi-square and uncertainty cuts are effective in cutting out a majority of the bad measurements, tricky cases may require a larger set of control light curves that can be used as a basis of comparison for inconsistent flux. In order to account for this inconsistent flux, we can obtain ~8 quality control forced photometry light curves in a 17\" circle pattern around the SN location OR around a nearby bright object that may be poorly subtracting. Then, we use statistics from these control light curves to cut bad measurements from the SN light curve.\n",
    "\n",
    "For a given epoch, we have 1 SN measurement for which we examine 8 control measurements within the same epoch. We know that if the control light curve measurements are NOT consistent with 0, this indicates something wrong with this epoch, so the SN measurement is unreliable. Therefore, we obtain statistics for the control light curves by calculating the 3σ-clipped average of the control flux. \n",
    "\n",
    "For the given epoch, we cut the SN measurement for which the returned control statistics fulfill any of the following criteria: \n",
    "- A returned chi-square > 2.5\n",
    "- A returned |flux/dflux| > 3.0\n",
    "- Number of clipped/\"bad\" measurements in the 3σ-clipped average > 2\n",
    "- Number of used/\"good\" measurements in the 3σ-clipped average < 4\n",
    "\n",
    "Measurements not fulfilling any of the criteria above but with Nclip > 0 are flagged as questionable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the bound for an epoch's maximum chi-square \n",
    "# (if chi-square value > x2_max, flag SN measurement):\n",
    "x2_max = 2.5\n",
    "\n",
    "# Enter the bound for an epoch's maximum abs(flux/dflux) ratio \n",
    "# (if |flux/dflux| > stn_max, flag SN measurement):\n",
    "stn_max = 3.0\n",
    "\n",
    "# Enter the bound for an epoch's maximum number of clipped control measurements\n",
    "# (if Nclip > Nclip_max, flag SN measurement):\n",
    "Nclip_max = 2\n",
    "\n",
    "# Enter the bound for an epoch's minimum number of good control measurements\n",
    "# (if Ngood < Ngood_min, flag SN measurement):\n",
    "Ngood_min = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_controls:\n",
    "    output = lc._apply_controls_cut(flags, x2_max, stn_max, Nclip_max, Ngood_min)\n",
    "    f = write_to_f(f, f'\\n\\n## Control light curve cut\\n{output}')\n",
    "else:\n",
    "    print('Load_controls set to False! Skipping...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the control light curve cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the light curve before and after the applied control light curve cut?:\n",
    "plot = True\n",
    "\n",
    "# Optionally, manually enter the x and y limits for the control light curve cut plot:\n",
    "xlim_lower = None\n",
    "xlim_upper = None\n",
    "ylim_lower = None\n",
    "ylim_upper = None\n",
    "\n",
    "if load_controls and plot:\n",
    "    limits = [xlim_lower, xlim_upper, ylim_lower, ylim_upper]\n",
    "    plot_cut_lc(lc, 'Control light curve cut', flags['controls_bad'], limits=limits, save_filename='controls_cut')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the ATLAS light curve with all previous cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the light curve before and after all cuts?:\n",
    "plot = True\n",
    "\n",
    "# Optionally, manually enter the x and y limits for the plot:\n",
    "xlim_lower = None\n",
    "xlim_upper = None\n",
    "ylim_lower = None\n",
    "ylim_upper = None\n",
    "\n",
    "if plot:\n",
    "    limits = [xlim_lower, xlim_upper, ylim_lower, ylim_upper]\n",
    "    plot_cut_lc(lc, 'Uncertainty, chi-square, and control light curve cuts', flags['uncertainty']|flags['chisquare']|flags['controls_bad'], limits=limits, save_filename='all_cut')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Averaging and cutting bad bins\n",
    "\n",
    "Our goal is to identify and cut out bad MJD bins by taking a 3σ-clipped average of each bin. For each bin, we calculate the 3σ-clipped average of any SN measurements falling within that bin and use that average as our flux for that bin. Because the ATLAS survey takes about 4 exposures every 2 days, we usually average together approximately 4 measurements per epoch. However, out of these 4 exposures, only measurements not cut in the previous methods are averaged in the 3σ-clipped average cut. (The exception to this statement would be the case that all 4 measurements are cut in previous methods; in this case, they are averaged anyway and flagged as a bad bin.)\n",
    "\n",
    "Then we cut any measurements in the SN light curve for the given epoch for which statistics fulfill any of the following criteria: \n",
    "- A returned chi-square > 4.0\n",
    "- Number of measurements averaged < 2\n",
    "- Number of measurements clipped > 1\n",
    "\n",
    "For this part of the cleaning, we still need to improve the cutting at the peak of the SN (important epochs are sometimes cut, maybe due to fast rise, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the MJD bin size in days:\n",
    "mjd_bin_size = 1\n",
    "\n",
    "# Should MJD bins with no measurements be translated as NaN (True) \n",
    "# or removed from the averaged light curve (False)?\n",
    "keep_empty_bins = True\n",
    "\n",
    "# After flux is averaged, average magnitudes are calculated using a flux-to-magnitude conversion.\n",
    "# Magnitudes are limits if the dmagnitude is NaN. Enter these magnitudes' sigma limit:\n",
    "flux2mag_sigmalimit = 3\n",
    "\n",
    "# Enter the bound for a bin's maximum number of clipped measurements\n",
    "# (if Nclip > Nclip_max, flag day):\n",
    "Nclip_max = 1\n",
    "\n",
    "# Enter the bound for a bin's minimum number of good measurements\n",
    "# (if Ngood < Ngood_min, flag day):\n",
    "Ngood_min = 2\n",
    "\n",
    "# Enter the bound for a bin's maximum chi-square (if x2 > x2_max, flag day):\n",
    "x2_max = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(lc.lcs[0].t) < 1:\n",
    "    print('ERROR: No data in lc so cannot average; exiting... ')\n",
    "    sys.exit()\n",
    "\n",
    "print('\\nAveraging light curve(s)...')\n",
    "avglc = CleanAtlasLightCurve(lc.filt, \n",
    "                             tnsname=lc.tnsname, \n",
    "\t\t\t\t\t\t\t is_averaged=True, \n",
    "\t\t\t\t\t\t\t mjd_bin_size=mjd_bin_size, \n",
    "\t\t\t\t\t\t\t discdate=lc.discdate)\n",
    "\n",
    "print('# Parameters: MJD bin size = %0.1f day(s), Nclip_max = %d, Ngood_min = %d, x2_max = %0.2f... ' % (mjd_bin_size, Nclip_max, Ngood_min, x2_max))\n",
    "for control_index in range(lc.num_controls+1):\n",
    "    avglc = lc._average(avglc, flags, Nclip_max, Ngood_min, x2_max, control_index=control_index, mjd_bin_size=mjd_bin_size, flux2mag_sigmalimit=flux2mag_sigmalimit)\n",
    "\n",
    "nonnull_ix = avglc.lcs[0].ix_not_null('MJD')\n",
    "percent_cut = 100 * len(avglc.lcs[0].ix_masked('Mask',maskval=flags['avg_badday'], indices=nonnull_ix)) / len(nonnull_ix)\n",
    "s = 'Total percent of binned data flagged (%s): %0.2f%%' % (hex(flags['avg_badday']), percent_cut) \n",
    "print(f'# {s}')\n",
    "output = f'{s}.'\n",
    "f.write(f'\\n\\n## Averaging cleaned light curves\\n{output}')\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the averaged light curve and bad day cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, manually enter the x and y limits for the averaged light curve plot:\n",
    "xlim_lower = None\n",
    "xlim_upper = None\n",
    "ylim_lower = None\n",
    "ylim_upper = None\n",
    "\n",
    "# Plot the averaged light curve before and after the bad day cut?\n",
    "plot = True\n",
    "\n",
    "if plot:\n",
    "    limits = [xlim_lower, xlim_upper, ylim_lower, ylim_upper]\n",
    "    plot_cut_lc(avglc, 'Averaged light curve', flags['avg_badday'], limits=limits, save_filename='averaged')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Correct for ATLAS reference template changes\n",
    "\n",
    "This notebook takes into account ATLAS's periodic replacement of the difference image reference templates, which may cause step discontinuities in flux. Two template changes have been recorded at MJDs 58417 and 58882. More information can be found here: https://fallingstar-data.com/forcedphot/faq/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True for ATLAS template change correction\n",
    "template_correction = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if template_correction:\n",
    "    print(lc.lcs[0].t.head().to_string())\n",
    "    plot_template_correction(lc, limits=[None]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally enter manual offsets for each region \n",
    "# (set each to None for automatic correction)\n",
    "global_offset = None\n",
    "region1_offset = None # global offset + x\n",
    "region2_offset = None # global offset + x\n",
    "region3_offset = None # global offset + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if template_correction:\n",
    "    output = lc.template_correction(maskval=0x1|0x2|0x400000|0x800000, \n",
    "                                    region1_offset=region1_offset, \n",
    "                                    region2_offset=region2_offset, \n",
    "                                    region3_offset=region3_offset)\n",
    "    print('\\n',lc.lcs[0].t[['MJD','uJy','uJy_offset','duJy']].head().to_string())\n",
    "    plot_template_correction(lc, limits=[None]*4)\n",
    "else:\n",
    "    print('Skipping template correction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if template_correction:\n",
    "    print(lc.lcs[0].t.head().to_string())\n",
    "    plot_template_correction(lc, limits=[None]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = write_to_f(f, f'\\n\\n## ATLAS template change correction\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: save the SN light curve with the new `'Mask'` and `'duJy_new'` columns\n",
    "\n",
    "Hex values in the `'Mask'` column for each cut's flag:\n",
    "- Uncertainty cut: 0x2\n",
    "- Chi-square cut: 0x1\n",
    "- Control light curve cut: 0x400000\n",
    "- Bad day (for averaged light curves): 0x800000\n",
    "\n",
    "You can combine these hex values together to create certain combinations of cuts that define a \"bad\" measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the SN and control light curves?:\n",
    "save_lc = False\n",
    "\n",
    "# save the SN and control averaged light curves?:\n",
    "save_avglc = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_lc:\n",
    "    print('Saving light curve with updated mask column...')\n",
    "    lc._save(source_dir, filt=filt, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_avglc:\n",
    "    print('Saving averaged light curve with updated mask column...')\n",
    "    avglc._save(source_dir, filt=filt, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and print summary of all cuts and corrections\n",
    "\n",
    "f.close()\n",
    "f1 = open(f'{source_dir}/{tnsname}/{tnsname}_output.md')\n",
    "content = f1.read()\n",
    "print()\n",
    "print(content)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
